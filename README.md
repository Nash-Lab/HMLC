 # Impact of Interval Censoring on Data Accuracy and Machine Learning Performance in High-Throughput Screening Experiments

 Data, Python scripts, Results and Figures used in the publication entitled "Impact of Interval Censoring on Data Accuracy and Machine Learning Performance in Biological High-Throughput Screening" (--> [preprint]()).

 - [Overview](#overview)
 - [Requirements](#requirements)
 - [Citation](#citation)


 ## Overview

 ### Data (on Zenodo)
 This folder (available on DOI:[10.5281/zenodo.13840800](http://doi.org/10.5281/zenodo.13840800)) contains the raw data used during this work.
 `EvoEF.csv` contains information on the library used (sequences, number of mutations, etc.) and the fitness (energy) used as continuous mean values. `mut.csv` contains the information about the combinatorial scaling (N vs N_norm), the number of mutations (m) and the probability of each variant using different distributions (uniform and binomial) at different $p_{WT}$.
 For further details on how the fitness values were calculated and how the combinatorial scale works, please refer to our prevoius [Paper](https://arxiv.org/abs/2405.05167).

 ### Scripts
 This folder contains the scripts used during this work.

`00_generate_summary_data.py` generates the data of the FACS mock experiment (Fig 1D).

`01_generate_2D_hist.py` generates the data of censoring effect on a single and theoretical distributed gaussian changing the normalized gate width and normalized gate position (Fig 2A-B and SFig 1A-B). 

`02_bias_vs_variance.py` generates the data of censoring effect on a single and realistically distributed gaussian changing the normalized gate width and the number of samples (Fig 3).

`03_pop_distr.py` generates the data of a library distribution (uniform and binomial distribution) changing the probability of the wild-type amino acids ($p_{WT}$).

`04_ML.py` generates the data used to study the population error distribution and the ML performance (Fig 4, SFig 3, 4 and 5).

`04_ML_merge_data.py` was used to merge the data generated by `04_ML.py` when the options `mode='single'` and `mode_rep='single'` were selected.

`SLURM_*` files were used to run the `04_*` scripts on a SLURM based cluster. 


 ### Results (on Zenodo)
 This folder (available on DOI:[10.5281/zenodo.13840800](http://doi.org/10.5281/zenodo.13840800)) contains the results (outputs) of all scripts used. Such results are included in the form of `.npy` and `.npz` files. To load such files with numpy you should include the option `allow_pickle=True`.

## Requirements
 The scripts have been run locally on an Intel-based MacBook Pro (macOS 13.6.7) and distributed in a CentOS and Ubuntu SLURM-based HPC cluster ([scicore website](https://scicore.unibas.ch)).

 To use our scripts, one should install the libraries in `environment.yml` with the following command (using anaconda or miniconda).

```
conda env create --file=environment.yml
```

## Citation
For usage of the code or data, and associated manuscript, please cite according to the enclosed [citation.bib](citation.bib).
